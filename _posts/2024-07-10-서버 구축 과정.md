---
title: 서버 구축 과정 정리
categories: [network , server management]
tags: [network , server management]
---

서버 관리자 교육 때 배운 서버 구축 과정을 정리 해보려 합니다.

스위치, 방화벽 설정은 추후 업데이트 할 예정입니다.

## 포맷

먼저 바이오스에 진입 후 포맷을 진행합니다. 우분투 22.04 버전으로 포맷을 진행 하였습니다. 

편의상 원격에서 진행하지만 초기에는 서버실에서 작업 해야 합니다. 

미리 세팅을 해두고 포스팅을 하는 것이기 때문에 별도의 언급이 있기 전까지는 서버실에서의 작업이라고 가정하겠습니다.

## IP 확인

![image](https://github.com/user-attachments/assets/4c48f5fc-245f-4dce-a76b-438c9a4c208e)

초반에는 ifconfig 명령을 사용할 수 없기 때문에 ip addr 로 ip 를 확인합니다. farm3 서버 같은 경우 eno1 의 ip 가 192.168.2.13/24 가 되어야 합니다. 지금은 세팅이 되어 있는 상황이지만 원래는 ip 가 없는 상태입니다. 따라서 우리는 수동으로 ip 를 할당 해주어야 합니다.

## IP 할당

```bash
cd /etc/netplan
sudo vim 01-network-manager-all.yaml
```

```bash
# Let NetworkManager manage all devices on this system

#아래와 동일하게 설정
network:
  ethernets:
    eno1:
      addresses: [192.168.2.13/24]
      gateway4: 192.168.2.1
  version: 2
  renderer: NetworkManager
```

위의 명령을 실행 후 다음과 같이 입력합니다. 대괄호를 생략하면 오류가 나기 때문에 꼭 포함 해주어야 합니다.

## Nameserver 설정

```bash
sudo vi /etc/resolv.conf
```

```bash
# This is /run/systemd/resolve/stub-resolv.conf managed by man:systemd-resolved(8).
# Do not edit.
#
# This file might be symlinked as /etc/resolv.conf. If you're looking at
# /etc/resolv.conf and seeing this text, you have followed the symlink.
#
# This is a dynamic resolv.conf file for connecting local clients to the
# internal DNS stub resolver of systemd-resolved. This file lists all
# configured search domains.
#
# Run "resolvectl status" to see details about the uplink DNS servers
# currently in use.
#
# Third party programs should typically not access this file directly, but only
# through the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a
# different way, replace this symlink by a static file or a different symlink.
#
# See man:systemd-resolved.service(8) for details about the supported modes of
# operation for /etc/resolv.conf.

#nameserver -> 8.8.8.8 로 설정
nameserver 8.8.8.8
options edns0 trust-ad
search .
```

이 부분에서 꽤 고생 했습니다.

 nameserver 값을 8.8.8.8 로 바꿔주지 않으면 인터넷 접속이 되지 않습니다.

```
ping 8.8.8.8
```

![image](https://github.com/user-attachments/assets/ecd1231a-e0be-4c7e-90db-2f3e2b4a5e7e)

다음과 같은 화면이 뜬다면 인터넷 접속이 되는 상태입니다.

## 패키지 설치

```bash
sudo apt install net-tools
sudo apt install curl
sudo apt install vim
sudo apt install wget
..
```

위 프로그램을 포함해서 각종 필요한 패키지를 설치 합니다.



## Ssh 설치

```bash
sudo apt update
sudo apt install openssh-server
```

먼저 ssh server 를 설치합니다.

```bash
sudo vim /etc/ssh/sshd_config
```

```bash
# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

Include /etc/ssh/sshd_config.d/*.conf

# port 번호 8083 으로 설정
Port 8083
# 해당 필드 추가 
AllowGroups sudo

#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

# Ciphers and keying
#RekeyLimit default none

# Logging
#SyslogFacility AUTH
#LogLevel INFO

# Authentication:

#LoginGraceTime 2m
#PermitRootLogin prohibit-password
```

다음은 Sshd_config 파일을 수정합니다. 포트 번호를 수정 해주고 allowgroups 필드를 추가 해주어야 외부 접속이 가능합니다.

```bash
sudo systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target
```

(추가로 서버의 자동 절전모드를 막기 위해 위 명령을 입력 하라고 합니다.)

설정을 모두 마쳤으면 외부 접속이 가능합니다. 이제 원격 계정을 생성 해보겠습니다.

## 원격 접속 계정 설정

```bash
sudo adduser [user]
```

```bash
sudo usermod -aG sudo [user]
	# usermod : user의 설정변경
  # usermod -G : user의 group 변경
	# -a : append
```

```bash
sudo cat /etc/group | grep sudo
# sudo group에 추가 되었는지 확인
```

순서 대로 실행 하면 됩니다. 이제 본인 계정으로 원격 접속이 가능합니다.

따라서 이 시점부터는 원격 접속을 통해 작업 하는 과정을 포스팅 하겠습니다.

(서버실에서 작업하는 것과 동일합니다.)

## Docker 설치

```bash
sudo apt-get update
```

```bash
sudo apt-get install -y \
		apt-transport-https \
		ca-certificates \
		curl \
		gnupg-agent \
		software-properties-common
```

```bash
wget -qO - https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
```

```bash
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
```

```bash
sudo add-apt-repository \
"deb [arch=amd64] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) \
stable"
```

```bash
sudo apt-get update &&
sudo apt-get install -y docker-ce docker-ce-cli containerd.io
```

위 명령을 차례로 입력 하고 docker 를 설치 합니다.



## Nvidia 그래픽 드라이버 설치

```bash
sudo ubuntu-drivers autoinstall
sudo apt-mark hold nvidia-driver
sudo reboot
```

원래는 위 명령으로 설치 되어야 합니다. 그런데 Ubuntu 22.04 가 자동으로 드라이버를 설치한 건지, 미리 설치가 되어 있었습니다.

## Nvidia-docker 설치

```bash
sudo dpkg -l | grep nvidia
# 아무것도 출력되지 않으면 설치 되어있지 않은 것.
```

```bash
curl https://get.docker.com | sh \ 
	  && sudo systemctl --now enable docker
```

```bash
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
   && curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \
   && curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
```

```bash
sudo apt-get update &&
sudo apt-get install -y nvidia-docker2 &&
sudo systemctl restart dockercd /et
```

```bash
# docker 테스트 코드
sudo docker run --rm --gpus all ubuntu:18.04 nvidia-smi

# 아래와 같은 화면이 나온다면 성공

Unable to find image 'ubuntu:18.04' locally
18.04: Pulling from library/ubuntu
7c457f213c76: Pull complete
Digest: sha256:152dc042452c496007f07ca9127571cb9c29697f42acbfad72324b2bb2e43c98
Status: Downloaded newer image for ubuntu:18.04
Tue Jun 13 05:14:41 2023
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN RTX                Off| 00000000:1A:00.0 Off |                  N/A |
| 41%   33C    P8               31W / 280W|      6MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA TITAN RTX                Off| 00000000:68:00.0 Off |                  N/A |
| 41%   34C    P8               23W / 280W|     15MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+
```

## NFS MOUNT

컨테이너를 할당하기 전에 마운트를 통해 NAS 와 연결 해주어야 합니다. 

```bash
# 파일이 없다면 파일 생성
mkdir /home/tako3
mkdir /home/tako3/share
```

```bash
sudo mount 192.168.2.30:/volume1/share /home/tako3/share
```

```bash
df -h

Filesystem                   Size  Used Avail Use% Mounted on
tmpfs                        6.3G  2.4M  6.3G   1% /run
/dev/sda2                    938G   25G  866G   3% /
tmpfs                         32G     0   32G   0% /dev/shm
tmpfs                        5.0M  4.0K  5.0M   1% /run/lock
efivarfs                     128K   91K   33K  74% /sys/firmware/efi/efivars
/dev/sda1                    511M  6.1M  505M   2% /boot/efi
tmpfs                        6.3G   80K  6.3G   1% /run/user/128
tmpfs                        6.3G   68K  6.3G   1% /run/user/1002
# 성공적으로 mount 되었다면 다음과 같은 화면이 출력
192.168.2.30:/volume1/share   25T   12T   14T  46% /home/tako3/share
```

만약 위 과정에서 오류가 발생하였다면 다음과 같이 하면 됩니다.

```bash
# 오류 내용
mount: /home/tako7/share: bad option; for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.<type> helper program.
# 해결책
sudo apt-get -y install nfs-common cifs-utils
sudo mount 192.168.2.30:/volume1/share /home/tako3/share
```

다음으로는 fstab 파일을 수정 해야 합니다.

```bash
sudo vim /etc/fstab
```

```bash
// <file system> <mount point>   <type>  <options>       <dump>  <pass>
192.168.2.30:/volume1/share /home/tako4/share nfs defaults 0 0
# 재부팅시에 위에서 설정한 nfs매핑이 default로 mount될 수 있도록 fstab파일을 수정
```

여기까지 하면 마운트가 완료 됩니다.



## Docker 컨테이너 할당

이제 사용자 관리 문서에서 decs1.4 & 1.4.18 탭으로 이동한 뒤 정보를 입력하고, 출력되는 명령어를 순차적으로 입력하면 됩니다.

성공적으로 입력 했다면 아래 명령어를 실행하여 컨테이너 실행 상태를 확인할 수 있습니다.

```bash
sudo docker ps
```

```bash
CONTAINER ID   IMAGE                  COMMAND                 CREATED       STATUS         PORTS                                                                              NAMES
d056360395a2   dguailab/decs:1.4.18   "bash /entrypoint.sh"   5 hours ago   Up 8 minutes   0.0.0.0:9200->22/tcp, :::9200->22/tcp, 0.0.0.0:9201->8888/tcp, :::9201->8888/tcp   testfarm3_bymingi
```

위와 같은 화면이 나온다면 성공입니다.

```bash
# ssh 접속 확인
ssh testfarm3@[container 외부 주소] -p 9200
```

![image](https://github.com/user-attachments/assets/7555619f-16a4-46f9-a40d-f81ea0c83394)

마지막으로 ssh 와 Jupyter 에서의 접속 여부를 확인하면 끝입니다.

## Docker 컨테이너 재시작

```bash
sudo docker restart [container name]
```

만약 중지된 container 를 다시 시작하고 싶다면 다음과 같은 명령어를 입력하면 됩니다.
